{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saYhadBGTAq1"
   },
   "source": [
    "# Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yn6Wz9iLS--O",
    "outputId": "6a1d9043-1911-4160-d302-cb5d83fb70a5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "# from distutils.version import LooseVersion\n",
    "# import warnings\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FIleuCAjoFD8",
    "outputId": "72bcf8b8-9443-4a31-a75c-5c146f85950b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0koUcJMJpEBD",
    "outputId": "56600112-fdef-40da-dc9d-d6463f36c84c",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/output/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3fe3bc1d477b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                    \u001b[0mzoom_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                    horizontal_flip = True)\n\u001b[1;32m----> 5\u001b[1;33m training_set = train_datagen.flow_from_directory('dataset/output/train',\n\u001b[0m\u001b[0;32m      6\u001b[0m                                                  \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    940\u001b[0m             \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m     \"\"\"\n\u001b[1;32m--> 942\u001b[1;33m     return DirectoryIterator(\n\u001b[0m\u001b[0;32m    943\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m     super(DirectoryIterator, self).__init__(\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset/output/train'"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/output/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SH4WzfOhpKc3",
    "outputId": "bddd276f-e33d-4806-b539-b089e1024473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18000 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/output/val',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "# cnn = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution 2D Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPzPrMckl-hV"
   },
   "outputs": [],
   "source": [
    "# cnn.add(keras.layers.Conv2D(filters=16, kernel_size=7, activation='elu', strides=3, input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Batch Normalisation Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB7tijsFSn4I"
   },
   "outputs": [],
   "source": [
    "# cnn.add(keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 3 - Max Pooling 2D Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncpqPl69mOac"
   },
   "outputs": [],
   "source": [
    "# cnn.add(keras.layers.MaxPool2D(pool_size=3, strides=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Repeating Step 1 , 2 & 3 three more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_-FZjn_m8gk"
   },
   "outputs": [],
   "source": [
    "# # Step 4 - Convolution 2D Layer 2\n",
    "# cnn.add(keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, activation='elu'))\n",
    "# # step 5 - Batch Normalisation Layer 2\n",
    "# cnn.add(keras.layers.BatchNormalization())\n",
    "# # step 6 - Max Pooling 2D Layer 2\n",
    "# cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=1))\n",
    "\n",
    "# # step 7 - Convolution 2D Layer 3\n",
    "# cnn.add(keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, activation='elu'))\n",
    "# # step 8 - Batch Normalisation Layer 3\n",
    "# cnn.add(keras.layers.BatchNormalization())\n",
    "# # step 9 - Max Pooling 2D Layer 3\n",
    "# cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=1))\n",
    "\n",
    "# # step 7 - Convolution 2D Layer 4\n",
    "# cnn.add(keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, activation='elu'))\n",
    "# # step 8 - Batch Normalisation Layer 4\n",
    "# cnn.add(keras.layers.BatchNormalization())\n",
    "# # step 9 - Max Pooling 2D Layer 4\n",
    "# cnn.add(keras.layers.MaxPool2D(pool_size=2, strides=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 10 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "# cnn.add(keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 11 - Full Connection (Dense Layer - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zulA0OVSn4R"
   },
   "outputs": [],
   "source": [
    "# cnn.add(keras.layers.Dense(units=128, activation='elu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12 - Full Connection (Dense Layer - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "# cnn.add(keras.layers.Dense(units=128, activation='elu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 13 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": [
    "# cnn.add(keras.layers.Dense(units=9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "# cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUj1W4PJptta",
    "outputId": "bb9f9fe7-5448-4d9e-eefd-4a60a3b36119"
   },
   "outputs": [],
   "source": [
    "# cnn.fit(training_set, validation_data = test_set, epochs = 25)\n",
    "\n",
    "#Training and testing finished here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UaoJa2QSn4X"
   },
   "outputs": [],
   "source": [
    "# cnn.save('models/v3/v3-temp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJBKKrNZSn4Y"
   },
   "outputs": [],
   "source": [
    "# cnn.save_weights('models/v3/v3_temp_weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsSiWEJY1BPB"
   },
   "outputs": [],
   "source": [
    "# test_image = image.load_img('dataset/output/single_prediction/triangle-raw2.jpg', target_size = (64, 64))\n",
    "# test_image = image.img_to_array(test_image)\n",
    "# test_image = np.expand_dims(test_image, axis = 0)\n",
    "# result = cnn.predict(test_image)\n",
    "# training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = result.ravel() \n",
    "# for i in range(len(result)):\n",
    "#     print([result[i],keys[i]])\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ED9KB3I54c1i"
   },
   "outputs": [],
   "source": [
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = list(training_set.class_indices.keys())\n",
    "# print(keys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3U1_qjA8Sn4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 20, 20, 16)        2368      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 20, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 18, 18, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               166016    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 204,953\n",
      "Trainable params: 204,761\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('models/v3/v3-temp.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpNWw83mSn4c"
   },
   "outputs": [],
   "source": [
    "# get summary for weights\n",
    "\n",
    "# weights = model.load_weights('models/v3/v3_temp_weights.h5')\n",
    "# weights.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8wKH7fsSn4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/output/single_prediction/pentagon1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "#training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys = list(training_set.class_indices.keys())\n",
    "result = result.ravel() \n",
    "#for i in range(len(result)):\n",
    "    #print([result[i],keys[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain with 15 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrian with 15 more epochs \n",
    "\n",
    "# model.fit(training_set, validation_data = test_set, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new weights\n",
    "\n",
    "# cnn.save('models/v4/v4.h5')\n",
    "# cnn.save_weights('models/v4/v4_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 20, 20, 16)        2368      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 20, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 18, 18, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               166016    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 204,953\n",
      "Trainable params: 204,761\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load latest trained model with 15 more epochs\n",
    "model = load_model('models/v4/v4.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'circle': 0,\n",
       " 'heptagon': 1,\n",
       " 'hexagon': 2,\n",
       " 'nonagon': 3,\n",
       " 'octagon': 4,\n",
       " 'pentagon': 5,\n",
       " 'square': 6,\n",
       " 'star': 7,\n",
       " 'triangle': 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/output/single_prediction/octagon1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 'circle']\n",
      "[0.0, 'heptagon']\n",
      "[0.0, 'hexagon']\n",
      "[0.0, 'nonagon']\n",
      "[1.0, 'octagon']\n",
      "[0.0, 'pentagon']\n",
      "[0.0, 'square']\n",
      "[0.0, 'star']\n",
      "[0.0, 'triangle']\n"
     ]
    }
   ],
   "source": [
    "keys = list(training_set.class_indices.keys())\n",
    "result = result.ravel() \n",
    "for i in range(len(result)):\n",
    "    print([result[i],keys[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
